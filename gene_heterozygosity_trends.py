#!/usr/bin/env python3
'''
Generate expected and observed heterozygosity trends for every significant region.

Input
	--regressions-tsv     regressions table produced by save_regression_results
	--bed-prefix          prefix of PLINK BED/BIM/FAM files (without extension)
	--samples-csv         table with per-sample meta data (must include the date field)
	--output-tsv          file to write the trend data
	--bootstrap           number of bootstrap repeats (default 1000)
	--threads             threads for the bed_reader (default 4)

The script selects regions where
	significant == True  and  bootstrap_repeats >= confidence * 1000
'''

import argparse
import numpy as np
import pandas as pd
from pathlib import Path
from itertools import product
from concurrent.futures import ThreadPoolExecutor

from bed_reader import open_bed


def init_bed_reader(bed_prefix, samples, threads):
	'''
	Return (bed_file, sample_indices, bim)

	sample_indices follow the order of `samples`.
	bim holds the chromosome / position columns loaded with pandas
	to avoid the slow np.loadtxt call inside bed_reader.
	'''
	bed_file = open_bed(f'{bed_prefix}.bed', num_threads = threads)
	bim = pd.read_csv(
		f'{bed_prefix}.bim',
		sep   = r'\s+',
		usecols = [0, 3],
		names = ['chr', 'pos'],
		dtype = {'chr': str, 'pos': np.int32}
	)
	iid = bed_file.iid
	common, idx_samples, idx_iid = np.intersect1d(samples, iid, return_indices = True)
	if len(common) < len(samples):
		raise KeyError('Some samples not found in FAM file')
	order = np.argsort(idx_samples)
	sample_indices = idx_iid[order].astype(np.int32)
	return bed_file, sample_indices, bim


def load_genotypes(bed_file, sample_idx, bim, chrom, start_pos, end_pos):
	'''
	Return genotype matrix (variants x samples) for region.
	'''
	variant_indices = np.where((bim['chr'].values == chrom) & (bim['pos'].values >= start_pos) & (bim['pos'].values < end_pos))[0]
	genotypes = bed_file.read(np.s_[sample_idx, variant_indices], dtype='int8')
	pos = bim['pos'].values[variant_indices]
	return genotypes.T, pos


def process_region(region_row, bed_file, sample_idx, bim, sample_dates, bootstrap_n):
	chrom = region_row['chr']
	start = region_row['start']
	end = region_row['end']
	genotypes, _ = load_genotypes(bed_file, sample_idx, bim, chrom, start, end)
	results = []
	windows = np.arange(12000, 1500, -500)
	for win_start in windows:
		mask = (sample_dates <= win_start) & (sample_dates > win_start - 2000)
		sel = np.where(mask)[0]
		if len(sel) < 10:
			continue
		for repeat in range(bootstrap_n + 1):
			if repeat:
				sel_rep = np.random.choice(sel, len(sel), replace=True)
			else:
				sel_rep = sel
			g_sel = genotypes[:, sel_rep]
			not_miss = g_sel != -127
			if not not_miss.any():
				continue
			allele_counts = np.where(not_miss, g_sel, 0)
			var_count = not_miss.sum(axis=1)
			p = allele_counts.sum(axis=1) / (var_count * 2)
			h_exp = np.nanmean(2 * p * (1 - p))
			sample_cov = not_miss.sum(axis=0)
			h_obs = ((allele_counts == 1).sum(axis=0) / sample_cov).mean()
			results.append([region_row['name'], repeat, win_start,
							win_start - 2000, h_exp, h_obs])
	return results


def main():
	parser = argparse.ArgumentParser(description='Generate trends data for regions that are significant in beta_H regressions')
	parser.add_argument('--regressions-tsv', required=True, help='File containing the results of the heterozygosity pipeline')
	parser.add_argument('--bed-prefix', required=True, help='PLINK file generated by impute_genotypes')
	parser.add_argument('--samples-csv', required=True, help='Samples file containing the date of the samples (column name=date)')
	parser.add_argument('--output-tsv', required=True, help='Output file containing lines per significant region, per temporal window')
	parser.add_argument('--bootstrap', type=int, default=1000, help='Bootstrap iterations for CIs of heterozygosity')
	parser.add_argument('--regression-confidence', type=float, default=0.95, help='Include only regions with significance in at least X% of bootstrapped repeats')
	parser.add_argument('--threads', type=int, default=4)
	args = parser.parse_args()

	regions = pd.read_csv(args.regressions_tsv, sep='\t', dtype = {'chr': str, 'start': int, 'end': int})
	regions_sig = regions[(regions['significant']) & (regions['bootstrap_repeats'] >= 1000 * args.regression_confidence)]

	samples = pd.read_csv(args.samples_csv, sep='\t', index_col=0)
	sample_dates = samples['date'].to_numpy()
	bed_file, sample_idx, bim = init_bed_reader(args.bed_prefix, samples.index, args.threads)

	all_results = []
	with ThreadPoolExecutor(max_workers=args.threads) as pool:
		futures = []
		for _, region_row in regions_sig.iterrows():
			futures.append(pool.submit(process_region, region_row, bed_file, sample_idx, bim, sample_dates, args.bootstrap))
		for fut in futures:
			all_results.extend(fut.result())

	out_df = pd.DataFrame(all_results, columns=['name', 'repeat', 'window_start', 'window_end', 'h_exp', 'h_obs_mean'])
	out_df.to_csv(args.output_tsv, sep='\t', index=False)


if __name__ == '__main__':
	main()
